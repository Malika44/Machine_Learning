{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T18:46:04.034641Z",
     "start_time": "2023-07-05T18:46:04.022211Z"
    }
   },
   "outputs": [],
   "source": [
    "# \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T18:20:32.770894Z",
     "start_time": "2023-07-05T18:20:32.751368Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "filename = \"./Data/ComputerHardware/machine.data\"\n",
    "names = \"./Data/ComputerHardware/machine.names\"\n",
    "names = [\"vendor name\", \"Model Name\", \"MYCT\", \"MMIN\", \"MMAX\", \"CACH\", \"CHMIN\", \"CHMAX\", \"PRP\", \"ERP\"]\n",
    "dataset = pd.read_csv(filename, names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Validation and Hyperparameter Search with LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- KFold cross-validation\n",
    "- GridSearchCV and RandomizedSearchCV\n",
    "- Different preprocessing options (StandardScaler, MinMaxScaler)\n",
    "- Handling categorical columns (drop vs. one-hot encoding)\n",
    "- LinearRegression hyperparameters (fit_intercept, normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.copy()\n",
    "y = X[\"PRP\"]\n",
    "X = X.drop(columns=[\"PRP\", \"ERP\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnsDroper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns_to_drop: list):\n",
    "        self.columns_to_drop = columns_to_drop\n",
    "    \n",
    "    def drop_columns(self, X):\n",
    "        X = X.drop(self.columns_to_drop, axis=1)\n",
    "        return(X)\n",
    "        \n",
    "\n",
    "    def fit(self, X:pd.DataFrame, y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y = None):\n",
    "        X = self.drop_columns(X)\n",
    "        return(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Drop categorical columns\n",
    "drop_cat = ColumnsDroper([\"vendor name\", \"Model Name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Encode categorical columns\n",
    "cat_features = [\"vendor name\", \"Model Name\"]\n",
    "cat_encoder = make_column_transformer(\n",
    "    (OneHotEncoder(handle_unknown=\"ignore\"), cat_features),\n",
    "    remainder=\"passthrough\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing options\n",
    "scalers = {\n",
    "    \"standard\": StandardScaler(),\n",
    "    \"minmax\": MinMaxScaler()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pipelines for grid search\n",
    "pipelines = {\n",
    "    \"drop_standard\": make_pipeline(\n",
    "        ColumnsDroper([\"vendor name\", \"Model Name\"]),\n",
    "        StandardScaler(),\n",
    "        LinearRegression()\n",
    "    ),\n",
    "    \"drop_minmax\": make_pipeline(\n",
    "        ColumnsDroper([\"vendor name\", \"Model Name\"]),\n",
    "        MinMaxScaler(),\n",
    "        LinearRegression()\n",
    "    ),\n",
    "    \"encode_standard\": make_pipeline(\n",
    "        cat_encoder,\n",
    "        StandardScaler(),\n",
    "        LinearRegression()\n",
    "    ),\n",
    "    \"encode_minmax\": make_pipeline(\n",
    "        cat_encoder,\n",
    "        MinMaxScaler(),\n",
    "        LinearRegression()\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold CV (drop_standard): -4719.553300618649 2695.549166896928\n"
     ]
    }
   ],
   "source": [
    "# KFold cross-validation with one pipeline\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "pipe = pipelines[\"drop_standard\"]\n",
    "scores = cross_val_score(pipe, X, y, cv=kf, scoring=\"neg_mean_squared_error\")\n",
    "print(\"KFold CV (drop_standard):\", scores.mean(), scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV: different preprocessing and LinearRegression options\n",
    "param_grid = [\n",
    "    {\n",
    "        \"columnsdroper__columns_to_drop\": [[\"vendor name\", \"Model Name\"]],\n",
    "        \"standardscaler\": [StandardScaler()],\n",
    "        \"linearregression__fit_intercept\": [True, False]\n",
    "    },\n",
    "    {\n",
    "        \"columnsdroper__columns_to_drop\": [[\"vendor name\", \"Model Name\"]],\n",
    "        \"minmaxscaler\": [MinMaxScaler()],\n",
    "        \"linearregression__fit_intercept\": [True, False]\n",
    "    },\n",
    "    {\n",
    "        \"columntransformer\": [cat_encoder],\n",
    "        \"standardscaler\": [StandardScaler()],\n",
    "        \"linearregression__fit_intercept\": [True, False]\n",
    "    },\n",
    "    {\n",
    "        \"columntransformer\": [cat_encoder],\n",
    "        \"minmaxscaler\": [MinMaxScaler()],\n",
    "        \"linearregression__fit_intercept\": [True, False]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Build a generic pipeline with all possible steps (some will be skipped depending on params)\n",
    "full_pipeline = Pipeline([\n",
    "    (\"columnsdroper\", ColumnsDroper([\"vendor name\", \"Model Name\"])),\n",
    "    (\"columntransformer\", \"passthrough\"),\n",
    "    (\"standardscaler\", \"passthrough\"),\n",
    "    (\"minmaxscaler\", \"passthrough\"),\n",
    "    (\"linearregression\", LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(full_pipeline, param_grid, cv=kf, scoring=\"neg_mean_squared_error\", n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best GridSearchCV score: -4719.5533006186415\n",
      "Best params: {'columnsdroper__columns_to_drop': ['vendor name', 'Model Name'], 'linearregression__fit_intercept': True, 'minmaxscaler': MinMaxScaler()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py39_ml/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "20 fits failed out of a total of 40.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/py39_ml/lib/python3.9/site-packages/pandas/core/indexes/base.py\", line 3805, in get_loc\n",
      "    return self._engine.get_loc(casted_key)\n",
      "  File \"index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7081, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7089, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "KeyError: 'vendor name'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/py39_ml/lib/python3.9/site-packages/sklearn/utils/_indexing.py\", line 364, in _get_column_indices\n",
      "    col_idx = all_columns.get_loc(col)\n",
      "  File \"/opt/conda/envs/py39_ml/lib/python3.9/site-packages/pandas/core/indexes/base.py\", line 3812, in get_loc\n",
      "    raise KeyError(key) from err\n",
      "KeyError: 'vendor name'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/py39_ml/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/envs/py39_ml/lib/python3.9/site-packages/sklearn/base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/opt/conda/envs/py39_ml/lib/python3.9/site-packages/sklearn/pipeline.py\", line 654, in fit\n",
      "    Xt = self._fit(X, y, routed_params, raw_params=params)\n",
      "  File \"/opt/conda/envs/py39_ml/lib/python3.9/site-packages/sklearn/pipeline.py\", line 588, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/opt/conda/envs/py39_ml/lib/python3.9/site-packages/joblib/memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/py39_ml/lib/python3.9/site-packages/sklearn/pipeline.py\", line 1551, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "  File \"/opt/conda/envs/py39_ml/lib/python3.9/site-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"/opt/conda/envs/py39_ml/lib/python3.9/site-packages/sklearn/base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/opt/conda/envs/py39_ml/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\", line 993, in fit_transform\n",
      "    self._validate_column_callables(X)\n",
      "  File \"/opt/conda/envs/py39_ml/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\", line 552, in _validate_column_callables\n",
      "    transformer_to_input_indices[name] = _get_column_indices(X, columns)\n",
      "  File \"/opt/conda/envs/py39_ml/lib/python3.9/site-packages/sklearn/utils/_indexing.py\", line 372, in _get_column_indices\n",
      "    raise ValueError(\"A given column is not a column of the dataframe\") from e\n",
      "ValueError: A given column is not a column of the dataframe\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/conda/envs/py39_ml/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [ -4719.55330062 -15668.80494897  -4719.55330062  -5851.84533799\n",
      "             nan             nan             nan             nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "grid.fit(X, y)\n",
    "print(\"Best GridSearchCV score:\", grid.best_score_)\n",
    "print(\"Best params:\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'columnsdroper__columns_to_drop': ['vendor name', 'Model Name'], 'linearregression__fit_intercept': True, 'standardscaler': StandardScaler()}\n",
      "{'columnsdroper__columns_to_drop': ['vendor name', 'Model Name'], 'linearregression__fit_intercept': False, 'standardscaler': StandardScaler()}\n",
      "{'columnsdroper__columns_to_drop': ['vendor name', 'Model Name'], 'linearregression__fit_intercept': True, 'minmaxscaler': MinMaxScaler()}\n",
      "{'columnsdroper__columns_to_drop': ['vendor name', 'Model Name'], 'linearregression__fit_intercept': False, 'minmaxscaler': MinMaxScaler()}\n",
      "{'columntransformer': ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('onehotencoder',\n",
      "                                 OneHotEncoder(handle_unknown='ignore'),\n",
      "                                 ['vendor name', 'Model Name'])]), 'linearregression__fit_intercept': True, 'standardscaler': StandardScaler()}\n",
      "{'columntransformer': ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('onehotencoder',\n",
      "                                 OneHotEncoder(handle_unknown='ignore'),\n",
      "                                 ['vendor name', 'Model Name'])]), 'linearregression__fit_intercept': False, 'standardscaler': StandardScaler()}\n",
      "{'columntransformer': ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('onehotencoder',\n",
      "                                 OneHotEncoder(handle_unknown='ignore'),\n",
      "                                 ['vendor name', 'Model Name'])]), 'linearregression__fit_intercept': True, 'minmaxscaler': MinMaxScaler()}\n",
      "{'columntransformer': ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('onehotencoder',\n",
      "                                 OneHotEncoder(handle_unknown='ignore'),\n",
      "                                 ['vendor name', 'Model Name'])]), 'linearregression__fit_intercept': False, 'minmaxscaler': MinMaxScaler()}\n"
     ]
    }
   ],
   "source": [
    "for params in grid.cv_results_['params']:\n",
    "    print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_[\"params\"].__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RandomizedSearchCV score: -4719.553300618643\n",
      "Best params: {'standardscaler': StandardScaler(), 'minmaxscaler': MinMaxScaler(), 'linearregression__fit_intercept': True, 'columnsdroper__columns_to_drop': ['vendor name', 'Model Name']}\n"
     ]
    }
   ],
   "source": [
    "# RandomizedSearchCV\n",
    "\n",
    "param_dist = {\n",
    "    \"columnsdroper__columns_to_drop\": [[\"vendor name\", \"Model Name\"]],\n",
    "    \"standardscaler\": [StandardScaler(), \"passthrough\"],\n",
    "    \"minmaxscaler\": [MinMaxScaler(), \"passthrough\"],\n",
    "    \"linearregression__fit_intercept\": [True, False]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(full_pipeline, param_distributions=param_dist, n_iter=8, cv=kf, scoring=\"neg_mean_squared_error\", random_state=42, n_jobs=-1)\n",
    "random_search.fit(X, y)\n",
    "print(\"Best RandomizedSearchCV score:\", random_search.best_score_)\n",
    "print(\"Best params:\", random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "258.425px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
